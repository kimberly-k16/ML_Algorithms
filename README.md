# Machine Learning Algorithms From Scratch
This repository contains from-scratch implementations of various machine learning algorithms, crafted during my time as a research assistant. The code serves as a learning tool for students, emphasizing the mathematical foundations behind algorithms.

## What's Inside?

- **Gradient Descent**  
  Dive deep into the engine of optimization. This implementation walks through the gradient-based learning process, step by step, to minimize the cost functions.

- **Ridge Regression**  
  Regularization made simple! Ridge regression adds a penalty term to reduce overfitting while keeping the implementation grounded in basic linear algebra.

- **Logistic Regression**  
  Forget the libraries for a second. See how logistic regression classifies data using basic math without needing the help of scikit-learn.

- **Decision Trees**  
  Branching out into supervised learning? This implementation constructs decision trees with simplicity and clarity. No shortcuts, just pure logic.

- **Random Forest Classifier**  
  Here you learn how to bootstrap multiple decision trees into a random forest and why that makes a difference in classification problems.

- **Random Forest Regression**  
  The same magic of random forests, now applied to regression. Learn how an ensemble of decision trees can improve prediction accuracy in continuous data.

- **Dense Neural Network**  
  Moving into deep learning, this implementation showcases how a dense neural network (multilayer perceptron) works from scratch, providing insights into forward and backward propagation.

