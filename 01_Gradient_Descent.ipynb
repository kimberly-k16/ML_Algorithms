{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175388c3",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641e9de",
   "metadata": {},
   "source": [
    "### 1.1. Starting Point\n",
    "\n",
    "In machine learning, our goal is to find the weights (parameters) of a model (e.g., linear regression) that minimize the error between our predictions and the actual values. This involves optimizing the weights to make the model's predictions as accurate as possible.\n",
    "\n",
    "For linear regression, we commonly use the squared error as a measure of how far off our predictions are. The objective is to adjust the weights to minimize this error. For a single data point, the difference between the predicted value and the actual value is referred to as the **loss**: \n",
    "\n",
    "$$\n",
    "(f(x_{i}) - y_{i})^2\n",
    "$$\n",
    "\n",
    "When calculating the error across all data points, this becomes the **cost function**:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (f(x_{i}) - y_{i})^2\n",
    "$$\n",
    "\n",
    "where $ m $ is the number of data points, and we divide by $ 2m $ instead of just $ m $ to simplify later calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f85ba",
   "metadata": {},
   "source": [
    "### 1.2. Minimizing the Cost Function\n",
    "\n",
    "The cost function depends on the weights of the model, typically denoted as $ \\theta$ (Theta) in machine learning. Our objective is to minimize the cost function with respect to $ \\theta $.\n",
    "\n",
    "To minimize any function, the first step is to compute its derivative. In this case, because we have multiple variables (weights), we compute the partial derivative with respect to each weight while treating the other weights as constants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27824e06",
   "metadata": {},
   "source": [
    "### 1.3. Gradient Descent: Deriving the Update Rules\n",
    "\n",
    "Let’s start with the cost function for linear regression:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_{0} + \\theta_{1}X_{1i} - y_{i})^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\theta_0 $ is the intercept,\n",
    "- $ \\theta_1 $ is the weight associated with predictor $ X_1 $.\n",
    "\n",
    "Expanding the squared term:\n",
    "\n",
    "$$\n",
    "(\\theta_{0} + \\theta_{1}X_{1i} - y_{i})^2 = \\theta_{0}^2 + 2\\theta_{0}\\theta_{1}X_{1i} + \\theta_{1}^2X_{1i}^2 - 2(y_{i}\\theta_{0} + y_{i}\\theta_{1}X_{1i}) + y_{i}^2\n",
    "$$\n",
    "\n",
    "Next, we compute the derivative of the cost function with respect to $ \\theta_0 $:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta_0 + \\theta_1X_{1i} - y_i)\n",
    "$$\n",
    "\n",
    "For $ \\theta_1 $, the derivative is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_1} = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta_0 + \\theta_1X_{1i} - y_i)X_{1i}\n",
    "$$\n",
    "\n",
    "The general form for any weight $ \\theta_j $ is:\n",
    "\n",
    "$$\n",
    "\\frac{1}{m} \\sum_{i=1}^{m} (f(x_{i}) - y_{i}) X_{ji}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ef043",
   "metadata": {},
   "source": [
    "### 1.4. Vectorized Form\n",
    "\n",
    "In practical implementations, especially when dealing with large datasets, it’s more efficient to use vectorized operations rather than loops. This allows the operations to be performed over entire matrices, leveraging the power of matrix multiplication for faster computations.\n",
    "\n",
    "The vectorized form of the gradient is:\n",
    "\n",
    "$$\n",
    "\\frac{1}{m} X^T \\times (X \\times \\theta - Y)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ X $ is the matrix of input features (size $ m \\times k $, where $ m $ is the number of samples and $ k $ is the number of predictors),\n",
    "- $ \\theta $ is the vector of weights (size $k \\times 1 $),\n",
    "- $ Y $ is the vector of true values (size $ m \\times 1 $).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98d74d",
   "metadata": {},
   "source": [
    "### 1.5. Gradient Descent Algorithm - Updating\n",
    "\n",
    "To implement gradient descent, we iteratively update the values of $ \\theta $ by subtracting a fraction of the gradient at each step. This fraction is controlled by the learning rate $ \\alpha $, which determines the step size.\n",
    "\n",
    "The update rule for $ \\theta_j $ is:\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\times \\frac{1}{m} \\sum_{i=1}^{m} (f(x_{i}) - y_{i}) X_{ji}\n",
    "$$\n",
    "\n",
    "Choosing the right learning rate is crucial for the success of gradient descent. If $ \\alpha $ is too large, gradient descent might overshoot the minimum, while if it’s too small, the algorithm will take too long to converge. The goal is to find a balance that ensures steady progress toward the minimum without diverging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d35fe",
   "metadata": {},
   "source": [
    "# 2. Implementation\n",
    "In this section, we will now compare the two approaches of implementing gradient descent: the **vectorized form** and the **iterative form**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8337c",
   "metadata": {},
   "source": [
    "### 2.1. Vectorized Implementation\n",
    "The **vectorized implementation** of gradient descent is highly efficient, as it leverages matrix operations to perform all the necessary calculations in one step. Using matrix multiplication, we can compute the predictions, errors, and parameter updates simultaneously for all training samples. This approach reduces the computational overhead by avoiding explicit loops over the dataset, making it much faster and scalable for larger datasets.\n",
    "\n",
    "In the code below, the `gradientDescentVec` function performs gradient descent by computing the gradient using the entire dataset at once and updating the parameter vector `theta` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentVec(X, y, alpha, iterations):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Add a column of ones to the input matrix X for the bias term (theta_0)\n",
    "    app_X = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((app_X, X))\n",
    "    \n",
    "    # Initialize the parameter vector theta with zeros\n",
    "    theta = np.zeros((X.shape[1], 1))\n",
    "    \n",
    "    # Perform gradient descent for the specified number of iterations\n",
    "    for i in range(iterations):\n",
    "        # Update theta using the vectorized gradient descent formula\n",
    "        theta = theta - alpha * (1/y.shape[0]) * (np.dot(X.T, (np.dot(X, theta) - y)))\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aca45f",
   "metadata": {},
   "source": [
    "### 2.2. Iterative Implementation\n",
    "\n",
    "The iterative implementation is more intuitive and closely follows the traditional step-by-step gradient descent procedure. In this version, we manually compute the predicted value, the error, and the parameter updates for each data point individually. This approach involves looping over each training sample and updating the parameters sequentially.\n",
    "\n",
    "While easier to understand, this method can be much slower for large datasets, as it performs the calculations in a nested loop (over both samples and features). The `gradientDescent` function below implements this iterative approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f6881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, alpha, iterations):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Add a column of ones to the input matrix X for the bias term (theta_0)\n",
    "    app_X = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((app_X, X))\n",
    "    \n",
    "    # Initialize the parameter vector theta with zeros\n",
    "    theta = np.zeros((X.shape[1], 1))\n",
    "    \n",
    "    # Perform gradient descent iteratively\n",
    "    for _ in range(iterations):\n",
    "        theta_update = np.array([0]*X.shape[0]*X.shape[1]).reshape(X.shape[1], X.shape[0])\n",
    "        \n",
    "        # Loop through each data point\n",
    "        for i in range(X.shape[0]):\n",
    "            pred_vals = X[i, :]\n",
    "            # Calculate the prediction for the current sample\n",
    "            prediction = sum([temp_theta*temp_X for temp_theta, temp_X in zip(theta.T.flatten().tolist(), list(pred_vals))])\n",
    "            pred_err = prediction - y[i]\n",
    "            \n",
    "            # Calculate the update for each parameter\n",
    "            for j in range(X.shape[1]):\n",
    "                temp_theta_update = pred_err * pred_vals[j]\n",
    "                theta_update[j, i] = temp_theta_update\n",
    "                \n",
    "        # Update theta by averaging across all data points\n",
    "        theta_update = np.sum(theta_update, axis=1)\n",
    "        theta_update = theta_update / X.shape[0]\n",
    "        theta = theta - alpha * theta_update.reshape(-1, 1)\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cccffb",
   "metadata": {},
   "source": [
    "# 3.  Comparing the Two Approaches: Vectorized vs Iterative Gradient Descent\n",
    "\n",
    "Now, let's compare the execution time of the vectorized and iterative implementations of gradient descent. We'll use the `%%time` magic command to measure the time it takes for each approach to run on a real dataset.\n",
    "\n",
    "We will use the **Diabetes dataset** from `sklearn.datasets` for this comparison. This dataset contains 10 features and 442 samples, making it suitable for evaluating the performance difference between the two methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fd95b",
   "metadata": {},
   "source": [
    "#### Timing the Iterative Implementation\n",
    "\n",
    "Let's first measure the time taken by the **iterative** version of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5f9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.59 s\n",
      "Wall time: 1.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21.13227376],\n",
       "       [ 0.09649548],\n",
       "       [ 0.02845023],\n",
       "       [ 0.33065385],\n",
       "       [ 0.25152262],\n",
       "       [ 0.12353167],\n",
       "       [ 0.09964932],\n",
       "       [-0.20832127],\n",
       "       [ 0.25519683],\n",
       "       [ 0.31321041],\n",
       "       [ 0.20956109]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "theta_iterative = gradientDescent(X, y.reshape(-1, 1), alpha=0.001, iterations=150)\n",
    "theta_iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e2552",
   "metadata": {},
   "source": [
    "#### Timing the Vectorized Implementation\n",
    "Now, we'll measure the time taken by the vectorized implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541ad180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21.20080773],\n",
       "       [ 0.10314334],\n",
       "       [ 0.02359212],\n",
       "       [ 0.32205638],\n",
       "       [ 0.24243012],\n",
       "       [ 0.11636862],\n",
       "       [ 0.09550798],\n",
       "       [-0.21677578],\n",
       "       [ 0.23632567],\n",
       "       [ 0.31073748],\n",
       "       [ 0.21000291]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y = True)\n",
    "\n",
    "theta_Vec = gradientDescentVec(X, y.reshape(-1, 1), .001, 150)\n",
    "theta_Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46bc79",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "By comparing the output times from both methods, we can see how the vectorized approach performs significantly faster than the iterative one, especially as the dataset size increases. The vectorized approach leverages NumPy’s optimized operations for matrix multiplication, making it more suitable for large-scale data, while the iterative method may become slower as the number of samples and features grows.\n",
    "\n",
    "It should also be noted that the produced weights (theta matrices) are nearly identical in both implementations. This indicates that both methods converge to the same solution, confirming that the gradient descent algorithm is functioning correctly in both cases. The key advantage of the vectorized approach lies in its computational efficiency, which becomes increasingly important with larger datasets and higher-dimensional feature spaces.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
